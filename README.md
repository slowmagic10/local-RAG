# LLM_RAG_Model_Deployment

python3 -m venv .venv  
source .venv/bin/activate  
which python  
python3 -m pip install --upgrade pip  

- model_path = https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF
- Embedding Model: https://huggingface.co/BAAI/bge-base-en-v1.5
- Hugging Face(ChatInterface) -> https://www.gradio.app/docs/chatinterface

Steps:
1. Creating a virtual environment managing the dependencies.
2. what .env file and and how to load secrets from .env file
3. how to configure and load llm models from local folder and using together api
4. how to modularize your code and create a vectore DB
5. Pydantic & What is fast api from concepts to code
6. What is gradio and how to create UIs using Gradio
7. Combine everything and create a fully functional LLM App.

