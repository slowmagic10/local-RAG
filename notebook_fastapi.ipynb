{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAPI:\n",
    "\n",
    "- FastAPI framework, high performance, easy to learn, fast to code, ready for production\n",
    "- Web framework for building APIs with Python 3.8+ based on standard Python type hints.\n",
    "- Interactive API docs (provided by Swagger UI)\n",
    "- Validation of data:\n",
    "Automatic and clear errors when the data is invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/hello/{name}\")\n",
    "async def hello(name:str):\n",
    "    return f\"Hello {name} \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous Code:\n",
    "\n",
    "Asynchronous code just means that the language üí¨ has a way to tell the computer / program ü§ñ that at some point in the code, \n",
    "it ü§ñ will have to wait for something else to finish somewhere else. Let's say that something else is called \"slow-file\" üìù.\n",
    "\n",
    "So, during that time, the computer can go and do some other work, while \"slow-file\" üìù finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LLMs' : ['OpenAI', 'Mistral'],\n",
    "    'NLP' : ['Bert', 'RoBerta'],\n",
    "    'ML' : ['Xgboost', 'Catboost']\n",
    "}\n",
    "\n",
    "@app.get(\"/get_models/{usecase}\")\n",
    "async def get_items(usecase:str):\n",
    "    return models.get(usecase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation:\n",
    "\n",
    "class AvailableModel(str, Enum):\n",
    "    LLMs = \"LLMs\"\n",
    "    NLP = \"NLP\"\n",
    "    ML = \"ML\"\n",
    "    \n",
    "@app.get(\"/get_models/{usecase}\")\n",
    "async def get_items(usecase: AvailableModel):\n",
    "    return models.get(usecase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    description: str | None = None\n",
    "    price: float\n",
    "    tax: float | None = None\n",
    "\n",
    "@app.post(\"/items/\")\n",
    "async def create_item(item: Item):\n",
    "    return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/mistral-7b-instruct-v0.1.Q2_K.gguf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('MODEL_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load the model: 0.014013051986694336\n"
     ]
    }
   ],
   "source": [
    "local_mistal = llms.get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mistral = llms.get_llm_together()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Together(together_api_key=SecretStr('**********'), model='mistralai/Mistral-7B-Instruct-v0.2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.build_rag import RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.populate_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = rag.get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x2a735f220>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
